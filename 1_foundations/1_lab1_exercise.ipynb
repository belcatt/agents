{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If five cats can catch five mice in five minutes, how many cats are needed to catch 100 mice in 100 minutes?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's first identify what we're given and what we need to find.\n",
      "\n",
      "**Given:**\n",
      "- 7 people complete the task in 4 hours.\n",
      "- 5 machines complete the same task in 3 hours.\n",
      "\n",
      "**Find:**\n",
      "- How many hours will it take for 3 people and 2 machines working together to complete the task?\n",
      "\n",
      "---\n",
      "\n",
      "### Step 1: Determine individual work rates\n",
      "\n",
      "Define the total work as 1 task.\n",
      "\n",
      "- Rate of 7 people working together:\n",
      "\\[\n",
      "\\text{Rate}_{7p} = \\frac{1 \\text{ task}}{4 \\text{ hours}} = \\frac{1}{4} \\text{ tasks/hour}\n",
      "\\]\n",
      "\n",
      "- Rate of 5 machines working together:\n",
      "\\[\n",
      "\\text{Rate}_{5m} = \\frac{1 \\text{ task}}{3 \\text{ hours}} = \\frac{1}{3} \\text{ tasks/hour}\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### Step 2: Find the rate of one person and one machine\n",
      "\n",
      "Since rates are additive and people/machines are identical:\n",
      "\n",
      "- Rate of one person:\n",
      "\\[\n",
      "r_p = \\frac{\\text{Rate}_{7p}}{7} = \\frac{1/4}{7} = \\frac{1}{28} \\text{ tasks/hour}\n",
      "\\]\n",
      "\n",
      "- Rate of one machine:\n",
      "\\[\n",
      "r_m = \\frac{\\text{Rate}_{5m}}{5} = \\frac{1/3}{5} = \\frac{1}{15} \\text{ tasks/hour}\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### Step 3: Find the combined rate of 3 people and 2 machines\n",
      "\n",
      "\\[\n",
      "\\text{Rate}_{3p + 2m} = 3 \\times r_p + 2 \\times r_m = 3 \\times \\frac{1}{28} + 2 \\times \\frac{1}{15}\n",
      "\\]\n",
      "\n",
      "Calculate each term:\n",
      "\n",
      "\\[\n",
      "3 \\times \\frac{1}{28} = \\frac{3}{28}\n",
      "\\]\n",
      "\\[\n",
      "2 \\times \\frac{1}{15} = \\frac{2}{15}\n",
      "\\]\n",
      "\n",
      "Sum:\n",
      "\n",
      "\\[\n",
      "\\frac{3}{28} + \\frac{2}{15} = \\frac{3 \\times 15}{28 \\times 15} + \\frac{2 \\times 28}{15 \\times 28} = \\frac{45}{420} + \\frac{56}{420} = \\frac{101}{420}\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### Step 4: Find the time to complete the task at the combined rate\n",
      "\n",
      "\\[\n",
      "\\text{Time} = \\frac{1 \\text{ task}}{\\text{Rate}_{3p + 2m}} = \\frac{1}{\\frac{101}{420}} = \\frac{420}{101} \\approx 4.1584 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### **Answer:**\n",
      "\n",
      "It will take approximately **4.16 hours** for 3 people working together with 2 machines to complete the task.\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's first identify what we're given and what we need to find.\n",
       "\n",
       "**Given:**\n",
       "- 7 people complete the task in 4 hours.\n",
       "- 5 machines complete the same task in 3 hours.\n",
       "\n",
       "**Find:**\n",
       "- How many hours will it take for 3 people and 2 machines working together to complete the task?\n",
       "\n",
       "---\n",
       "\n",
       "### Step 1: Determine individual work rates\n",
       "\n",
       "Define the total work as 1 task.\n",
       "\n",
       "- Rate of 7 people working together:\n",
       "$$\n",
       "\\text{Rate}_{7p} = \\frac{1 \\text{ task}}{4 \\text{ hours}} = \\frac{1}{4} \\text{ tasks/hour}\n",
       "$$\n",
       "\n",
       "- Rate of 5 machines working together:\n",
       "$$\n",
       "\\text{Rate}_{5m} = \\frac{1 \\text{ task}}{3 \\text{ hours}} = \\frac{1}{3} \\text{ tasks/hour}\n",
       "$$\n",
       "\n",
       "---\n",
       "\n",
       "### Step 2: Find the rate of one person and one machine\n",
       "\n",
       "Since rates are additive and people/machines are identical:\n",
       "\n",
       "- Rate of one person:\n",
       "$$\n",
       "r_p = \\frac{\\text{Rate}_{7p}}{7} = \\frac{1/4}{7} = \\frac{1}{28} \\text{ tasks/hour}\n",
       "$$\n",
       "\n",
       "- Rate of one machine:\n",
       "$$\n",
       "r_m = \\frac{\\text{Rate}_{5m}}{5} = \\frac{1/3}{5} = \\frac{1}{15} \\text{ tasks/hour}\n",
       "$$\n",
       "\n",
       "---\n",
       "\n",
       "### Step 3: Find the combined rate of 3 people and 2 machines\n",
       "\n",
       "$$\n",
       "\\text{Rate}_{3p + 2m} = 3 \\times r_p + 2 \\times r_m = 3 \\times \\frac{1}{28} + 2 \\times \\frac{1}{15}\n",
       "$$\n",
       "\n",
       "Calculate each term:\n",
       "\n",
       "$$\n",
       "3 \\times \\frac{1}{28} = \\frac{3}{28}\n",
       "$$\n",
       "$$\n",
       "2 \\times \\frac{1}{15} = \\frac{2}{15}\n",
       "$$\n",
       "\n",
       "Sum:\n",
       "\n",
       "$$\n",
       "\\frac{3}{28} + \\frac{2}{15} = \\frac{3 \\times 15}{28 \\times 15} + \\frac{2 \\times 28}{15 \\times 28} = \\frac{45}{420} + \\frac{56}{420} = \\frac{101}{420}\n",
       "$$\n",
       "\n",
       "---\n",
       "\n",
       "### Step 4: Find the time to complete the task at the combined rate\n",
       "\n",
       "$$\n",
       "\\text{Time} = \\frac{1 \\text{ task}}{\\text{Rate}_{3p + 2m}} = \\frac{1}{\\frac{101}{420}} = \\frac{420}{101} \\approx 4.1584 \\text{ hours}\n",
       "$$\n",
       "\n",
       "---\n",
       "\n",
       "### **Answer:**\n",
       "\n",
       "It will take approximately **4.16 hours** for 3 people working together with 2 machines to complete the task."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def show_answer(answer: str):\n",
    "    # Convert \\[ ... \\] and \\( ... \\) to $$ ... $$ for MathJax\n",
    "    answer = re.sub(r'\\\\\\[(.*?)\\\\\\]', r'$$\\1$$', answer, flags=re.DOTALL)\n",
    "    answer = re.sub(r'\\\\\\((.*?)\\\\\\)', r'$\\1$', answer, flags=re.DOTALL)\n",
    "    display(Markdown(answer))\n",
    "\n",
    "# Example:\n",
    "show_answer(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A promising business area for an Agentic AI solution is **enterprise IT operations and incident management**. \n",
      "\n",
      "Why?  \n",
      "- IT environments are increasingly complex, with numerous interconnected systems generating vast amounts of data and incidents.  \n",
      "- Current tools often require manual intervention, slow root-cause analysis, and repetitive tasks.  \n",
      "- An Agentic AI could autonomously monitor systems, diagnose issues, execute remediation steps, and communicate updates with minimal human input.  \n",
      "- This would reduce downtime, accelerate incident resolution, and free IT staff to focus on strategic initiatives.  \n",
      "\n",
      "In summary, enterprise IT operations is ripe for an Agentic AI that acts proactively and autonomously to maintain system health.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# First create the messages:\n",
    "question = \"What is a business area that might be ripe for an Agentic AI solution?\"\n",
    "\n",
    "messages = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a concise, helpful and insightful product strategist.\"},\n",
    "  {\"role\": \"user\", \"content\": question},\n",
    "  ]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response1 = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response1.choices[0].message.content\n",
    "\n",
    "print(business_idea)\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Primary Pain Point:\n",
      " A specific primary pain point is **the slow and error-prone root cause analysis during IT incident resolution**, where manual triage delays fixes and increases downtime.  \n",
      "\n",
      "An Agentic AI can autonomously correlate logs, metrics, and alerts across systems to quickly identify the underlying cause and initiate targeted remediation steps, significantly reducing resolution time and human error.\n",
      "\n",
      "\n",
      "Agentic AI Solution:\n",
      " **MVP Plan for Agentic AI in IT Incident Root Cause Analysis**\n",
      "\n",
      "1. **Data Integration & Monitoring Setup**  \n",
      "   - Connect AI to a limited set of key IT systems and log sources (e.g., servers, network devices, application logs).  \n",
      "   - Implement continuous real-time data ingestion and alert monitoring.  \n",
      "   - *Success Metrics:* 90% data coverage of targeted systems; real-time data latency <1 min.  \n",
      "   - *Blockers:* Data format heterogeneity; access permissions and security constraints.\n",
      "\n",
      "2. **Automated Incident Correlation & Root Cause Identification**  \n",
      "   - Develop AI models to correlate alerts/logs and pinpoint probable root causes for common incident types.  \n",
      "   - *Success Metrics:* Root cause accuracy ≥70% on pilot incidents; average identification time <5 mins.  \n",
      "   - *Blockers:* Insufficient training data; complex or novel incident patterns.\n",
      "\n",
      "3. **Autonomous Remediation Recommendation Engine**  \n",
      "   - Provide AI-generated actionable remediation steps or runbooks for identified root causes.  \n",
      "   - *Success Metrics:* 80% of recommendations deemed relevant by IT staff; reduction in manual triage time by 30%.  \n",
      "   - *Blockers:* Variability in remediation procedures; risk aversion to automated suggestions.\n",
      "\n",
      "4. **Human-in-the-Loop Feedback Loop**  \n",
      "   - Enable IT teams to confirm, override, or refine AI findings and recommendations to improve model learning.  \n",
      "   - *Success Metrics:* User engagement rate ≥75%; model accuracy improvement of 10% after feedback cycles.  \n",
      "   - *Blockers:* User adoption resistance; complexity in feedback capture UX.\n",
      "\n",
      "5. **Pilot Deployment & Performance Monitoring**  \n",
      "   - Deploy MVP in a controlled IT environment and measure impact on incident resolution metrics.  \n",
      "   - *Success Metrics:* Incident resolution time reduced by ≥25%; number of incidents handled autonomously increases over time.  \n",
      "   - *Blockers:* Integration challenges; unexpected incident types not covered by MVP.\n",
      "\n",
      "---\n",
      "\n",
      "This phased MVP focuses on delivering clear, measurable value while iteratively addressing technical and adoption challenges.\n"
     ]
    }
   ],
   "source": [
    "# Keep the conversation context in mind\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": business_idea})\n",
    "\n",
    "# Follow up question that builds on the previous conversation:\n",
    "\n",
    "followup = (\n",
    "    \"Based on that business idea, suggest a specific primary pain point \\n or challenge that an Agentic AI is capable of providing a solution to provide value? \\nBe specific and concise.\"\n",
    ")\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": followup})\n",
    "\n",
    "# Ask it again\n",
    "\n",
    "response2 = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "pain_point = response2.choices[0].message.content\n",
    "print(\"\\n\\nPrimary Pain Point:\\n\", pain_point)\n",
    "\n",
    "# Now ask the LLM to propose an Agentic AI solution\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": pain_point})\n",
    "followup2 = (\"Sketch a 4-5 step MVP plan with success metrics and likely blockers.\")\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": followup2})\n",
    "\n",
    "# Ask it again\n",
    "\n",
    "response3 = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "roadmap = response3.choices[0].message.content\n",
    "print(\"\\n\\nAgentic AI Solution:\\n\", roadmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**MVP Plan for Agentic AI in IT Incident Root Cause Analysis**\n",
       "\n",
       "1. **Data Integration & Monitoring Setup**  \n",
       "   - Connect AI to a limited set of key IT systems and log sources (e.g., servers, network devices, application logs).  \n",
       "   - Implement continuous real-time data ingestion and alert monitoring.  \n",
       "   - *Success Metrics:* 90% data coverage of targeted systems; real-time data latency <1 min.  \n",
       "   - *Blockers:* Data format heterogeneity; access permissions and security constraints.\n",
       "\n",
       "2. **Automated Incident Correlation & Root Cause Identification**  \n",
       "   - Develop AI models to correlate alerts/logs and pinpoint probable root causes for common incident types.  \n",
       "   - *Success Metrics:* Root cause accuracy ≥70% on pilot incidents; average identification time <5 mins.  \n",
       "   - *Blockers:* Insufficient training data; complex or novel incident patterns.\n",
       "\n",
       "3. **Autonomous Remediation Recommendation Engine**  \n",
       "   - Provide AI-generated actionable remediation steps or runbooks for identified root causes.  \n",
       "   - *Success Metrics:* 80% of recommendations deemed relevant by IT staff; reduction in manual triage time by 30%.  \n",
       "   - *Blockers:* Variability in remediation procedures; risk aversion to automated suggestions.\n",
       "\n",
       "4. **Human-in-the-Loop Feedback Loop**  \n",
       "   - Enable IT teams to confirm, override, or refine AI findings and recommendations to improve model learning.  \n",
       "   - *Success Metrics:* User engagement rate ≥75%; model accuracy improvement of 10% after feedback cycles.  \n",
       "   - *Blockers:* User adoption resistance; complexity in feedback capture UX.\n",
       "\n",
       "5. **Pilot Deployment & Performance Monitoring**  \n",
       "   - Deploy MVP in a controlled IT environment and measure impact on incident resolution metrics.  \n",
       "   - *Success Metrics:* Incident resolution time reduced by ≥25%; number of incidents handled autonomously increases over time.  \n",
       "   - *Blockers:* Integration challenges; unexpected incident types not covered by MVP.\n",
       "\n",
       "---\n",
       "\n",
       "This phased MVP focuses on delivering clear, measurable value while iteratively addressing technical and adoption challenges."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(roadmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def save_html_report(\n",
    "    sections: dict,\n",
    "    filename: str = \"agentic_report.html\",\n",
    "    title: str = \"Agentic AI Brainstorm\"\n",
    "):\n",
    "    \"\"\"\n",
    "    sections: dict like {\n",
    "        \"Business Idea\": business_idea_markdown,\n",
    "        \"Primary Pain Point\": pain_point_markdown,\n",
    "        \"MVP Plan\": roadmap_markdown\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Merge sections into one Markdown document\n",
    "    md = f\"# {title}\\n\\n\"\n",
    "    for heading, body in sections.items():\n",
    "        md += f\"## {heading}\\n\\n{body}\\n\\n\"\n",
    "\n",
    "    # JSON-escape the Markdown for safe embedding in JS\n",
    "    md_js = json.dumps(md)\n",
    "\n",
    "    html = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "<meta charset=\"utf-8\" />\n",
    "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n",
    "<title>{title}</title>\n",
    "<!-- Minimal, readable styling -->\n",
    "<style>\n",
    "  :root {{\n",
    "    --bg: #0f172a;\n",
    "    --card: #111827;\n",
    "    --text: #e5e7eb;\n",
    "    --muted: #9ca3af;\n",
    "    --accent: #60a5fa;\n",
    "  }}\n",
    "  html, body {{\n",
    "    background: var(--bg);\n",
    "    color: var(--text);\n",
    "    margin: 0;\n",
    "    font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, \"Apple Color Emoji\",\"Segoe UI Emoji\";\n",
    "    line-height: 1.6;\n",
    "  }}\n",
    "  .container {{\n",
    "    max-width: 900px;\n",
    "    margin: 40px auto;\n",
    "    padding: 24px;\n",
    "    background: var(--card);\n",
    "    border-radius: 16px;\n",
    "    box-shadow: 0 10px 30px rgba(0,0,0,.3);\n",
    "  }}\n",
    "  h1, h2, h3 {{ line-height: 1.25; }}\n",
    "  h1 {{ font-size: 1.875rem; margin: 0 0 1rem; }}\n",
    "  h2 {{ font-size: 1.35rem; margin-top: 2rem; border-bottom: 1px solid #1f2937; padding-bottom: .4rem; }}\n",
    "  a {{ color: var(--accent); text-decoration: none; }}\n",
    "  pre, code {{\n",
    "    background: #0b1220;\n",
    "    border-radius: 8px;\n",
    "  }}\n",
    "  pre {{\n",
    "    padding: 12px;\n",
    "    overflow-x: auto;\n",
    "  }}\n",
    "  blockquote {{\n",
    "    margin: 0;\n",
    "    padding-left: 1rem;\n",
    "    border-left: 3px solid #374151;\n",
    "    color: var(--muted);\n",
    "  }}\n",
    "  .meta {{\n",
    "    color: var(--muted);\n",
    "    font-size: 0.9rem;\n",
    "    margin-bottom: 1rem;\n",
    "  }}\n",
    "</style>\n",
    "\n",
    "<!-- marked.js for Markdown rendering -->\n",
    "<script src=\"https://cdn.jsdelivr.net/npm/marked/marked.min.js\"></script>\n",
    "\n",
    "<!-- MathJax for LaTeX rendering -->\n",
    "<script>\n",
    "window.MathJax = {{\n",
    "  tex: {{ inlineMath: [['$', '$'], ['\\\\\\\\(', '\\\\\\\\)']], displayMath: [['$$','$$'], ['\\\\\\\\[','\\\\\\\\]']] }},\n",
    "  svg: {{ fontCache: 'global' }}\n",
    "}};\n",
    "</script>\n",
    "<script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js\"></script>\n",
    "</head>\n",
    "<body>\n",
    "  <div class=\"container\">\n",
    "    <div class=\"meta\">Generated report</div>\n",
    "    <div id=\"content\">Loading…</div>\n",
    "  </div>\n",
    "  <script>\n",
    "    const md = {md_js};\n",
    "    const html = marked.parse(md);\n",
    "    document.getElementById('content').innerHTML = html;\n",
    "    if (window.MathJax) {{\n",
    "      MathJax.typesetPromise();\n",
    "    }}\n",
    "  </script>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "\n",
    "    out = Path(filename).resolve()\n",
    "    out.write_text(html, encoding=\"utf-8\")\n",
    "    return str(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Volumes/HomeX/bcatt/gitDesk/agents/1_foundations/agentic_report.html\n"
     ]
    }
   ],
   "source": [
    "# Call the function with the sections\n",
    "# business_idea, pain_point, roadmap\n",
    "\n",
    "path = save_html_report(\n",
    "    {\n",
    "        \"Business Idea\": business_idea,\n",
    "        \"Primary Pain Point\": pain_point,\n",
    "        \"MVP Plan\": roadmap,\n",
    "    },\n",
    "    filename=\"agentic_report.html\",\n",
    "    title=\"Agentic AI – Opportunity & MVP\"\n",
    ")\n",
    "print(\"Saved:\", path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
